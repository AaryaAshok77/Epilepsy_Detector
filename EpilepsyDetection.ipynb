{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# The Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Dataset Acquisition & Understanding**\n",
    "\n",
    "- **Download the CHBM-MIT EEG dataset:** Go to [https://physionet.org/content/chbmit/](https://physionet.org/content/chbmit/) and follow the instructions to download the dataset.\n",
    "- **Familiarize yourself with the data:**\n",
    "  - Open the downloaded files in a text editor or use data exploration tools in Python like pandas.\n",
    "  - Identify the format of the data (e.g., EDF, CSV).\n",
    "  - Understand the channels, sampling rate, and meaning of each column in the data.\n",
    "  - Explore the provided annotation files and seizure labels.\n",
    "- **Choose environment:**\n",
    "  - **Macbook Air M1:** Install Python (version 3.7 or above) and the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Preprocessing & Feature Extraction**\n",
    "\n",
    "- **Import libraries:**\n",
    "\n",
    "```python\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "- **Load data:** Use mne functions like `mne.io.read_raw_edf` to load the EEG data.\n",
    "\n",
    "```python\n",
    "raw = mne.io.read_raw_edf('chb01_01.edf', preload=False)  # Replace with your filename\n",
    "```\n",
    "\n",
    "- **Cleaning and Filtering:**\n",
    "  - Apply basic filtering (e.g., notch filter to remove power line noise) using `raw.filter()`.\n",
    "  - Perform visual inspection (e.g., plotting the data) to identify and remove artifacts like muscle movement or equipment noise.\n",
    "  - Learn about advanced cleaning techniques like Independent Component Analysis (ICA) for advanced noise reduction.\n",
    "- **Resampling:**\n",
    "  - If needed, resample the data to a consistent sampling rate using `raw.resample()`\n",
    "- **Segmentation:**\n",
    "  - Use event markers or annotations to segment the data into relevant epochs (e.g., ictal and interictal periods) using `mne.Epochs`.\n",
    "  - Consider different epoch lengths based on your chosen features and seizure type.\n",
    "- **Feature Extraction:**\n",
    "  - Implement functions to calculate desired time-domain features (e.g., mean, variance, amplitude) and frequency-domain features (e.g., power spectral density using FFT) using libraries like NumPy or scikit-learn.\n",
    "  - Explore libraries like NeuroKit2 for specific EEG feature extraction functionalities.\n",
    "  - Consider advanced features like connectivity metrics (coherence, phase lag) using MNE-Python for later source localization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Testing Different Models**\n",
    " - **Import libraries:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of CHBM-MIT EEG Dataset\n",
    "### Dataset: Scalp EEG Recordings from Children with Intractable Seizures\n",
    "\n",
    "This dataset contains electroencephalography (EEG) recordings from **22 subjects** with intractable seizures. The data is grouped into **23 cases**, with some subjects contributing multiple recordings.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **Subjects:** 22 (5 males, 17 females; ages 1.5-22)\n",
    "* **Cases:** 23 (chb01 to chb23)\n",
    "* **Sampling Frequency:** 256 Hz\n",
    "* **Recordings per Subject:** 9-42 (each lasting 1-4 hours)\n",
    "* **Seizures:** 198 total (182 in original set)\n",
    "* **File Types:**\n",
    "    * `.edf`: Raw EEG data files (664 total)\n",
    "    * `.seizure`: Annotations for seizure start and end times (for files containing seizures)\n",
    "\n",
    "**Additional Notes:**\n",
    "\n",
    "* Case `chb21` is from the same subject as `chb01`, but recorded 1.5 years later.\n",
    "* Case `chb24` is not included in the `SUBJECT-INFO` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "LOCAL_PATH = os.getenv(\"LOCAL_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? Load the data from the records.txt file\n",
    "records_txt = LOCAL_PATH + 'RECORDS'\n",
    "with open(records_txt, 'r') as file:\n",
    "    records_path = [LOCAL_PATH + line.strip() for line in file]\n",
    "print(len(records_path), records_path)\n",
    "\n",
    "#? Load the data from the records-with-seizures.txt file\n",
    "records_seizure_txt = LOCAL_PATH + 'RECORDS-WITH-SEIZURES'\n",
    "with open(records_seizure_txt, 'r') as file:\n",
    "    records_seizure_path = [LOCAL_PATH + line.strip() for line in file]\n",
    "records_seizure_path.pop() #* Remove the last element which is an empty string\n",
    "print(len(records_seizure_path), records_seizure_path)\n",
    "\n",
    "#? Get the records that are not in the records-with-seizures.txt file\n",
    "records_seizure_set = set(records_seizure_path) #* Convert records_seizure_path to a set for faster lookup\n",
    "records_normal_path = [record for record in records_path if record not in records_seizure_set]\n",
    "print(len(records_normal_path), records_normal_path)\n",
    "\n",
    "#? Load the chbxx-summary.txt file\n",
    "summary_files = glob(LOCAL_PATH + '*/chb*-summary.txt')\n",
    "summary_files.sort()\n",
    "print(len(summary_files), summary_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib qt\n",
    "rawEEG = mne.io.read_raw_edf(records_path[0], preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rawEEG.plot(block=False, duration=5, title=\"rawEEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawEEG.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "filteredEEG = rawEEG.copy().filter(.05, 45)\n",
    "filteredEEG.plot(block=False, duration=5, title=\"Filtered rawEEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Seizure label to the columns based on the summary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting seizure times from summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seizure_data(file):\n",
    "    seizure_data = []\n",
    "    with open(file, 'r') as f:\n",
    "            block = f.read().split('\\n\\n')\n",
    "            for text in block:\n",
    "                num_seizures = re.findall(r'Number of Seizures in File: (\\d+)', text)\n",
    "                if num_seizures:\n",
    "                    for i in range(1, int(num_seizures[0])+1):\n",
    "                        name = re.findall(r'File Name: (.*\\.edf)', text)\n",
    "                        start_time = re.findall(r'Seizure {} Start Time: (\\d+) seconds'.format(i), text)\n",
    "                        end_time = re.findall(r'Seizure {} End Time: (\\d+) seconds'.format(i), text)\n",
    "                        if name and start_time and end_time:\n",
    "                            seizure_data.append([name[0], int(start_time[0]), int(end_time[0])])\n",
    "    return pd.DataFrame(seizure_data, columns=['name', 'seizure_start', 'seizure_end'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizures = get_seizure_data(summary_files[0])\n",
    "seizures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the DF to include the seizure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the DF to include the seizure data\n",
    "def add_seizure(table, patient):\n",
    "    # Extract the patient file and patient identifier\n",
    "    patient_file = patient.split('/')[-1]\n",
    "    patient_id = patient.split('/')[-1].split('_')[0]\n",
    "\n",
    "    #Special case for chb17\n",
    "    # /Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb-mit-scalp-eeg-database-1.0.0/chb17a/chb17a-summary.txt\n",
    "    if patient_id == 'chb17a'or patient_id == 'chb17b' or patient_id == 'chb17c':\n",
    "        patient_id = 'chb17'\n",
    "    \n",
    "    # Construct the path to the patient's summary file\n",
    "    patient_summary_file = LOCAL_PATH + patient_id + \"/\" + patient_id + '-summary.txt'\n",
    "    \n",
    "    # Get seizure data\n",
    "    seizures = get_seizure_data(patient_summary_file)\n",
    "    \n",
    "    # Initialize the 'seizure' column in the table\n",
    "    table['seizure'] = 0\n",
    "    \n",
    "    # Update the 'seizure' column based on the seizure data\n",
    "    for name, start, end in seizures[['name', 'seizure_start', 'seizure_end']].values:\n",
    "        if name == patient_file:\n",
    "            print(name, start, end)\n",
    "            table.loc[(table['time'] >= start) & (table['time'] <= end), 'seizure'] = 1\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edf -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? Convert the edf files to a numpy array\n",
    "def read_edf(file):\n",
    "    data = mne.io.read_raw_edf(file, preload=True) #* Load the data\n",
    "    data.set_eeg_reference() #* Set the reference to the average of the channels\n",
    "    data.filter(l_freq=0.5, h_freq=45) #* Filter the data to remove noise and artifacts and to get the frequency band of interest (0.5-45Hz)\n",
    "    data = data.to_data_frame() #* Convert the data to a pandas dataframe\n",
    "    common_cols = ['time','F7-T7','T7-P7','P7-O1','FP1-F3','F3-C3','C3-P3','P3-O1','FP2-F4','F4-C4','C4-P4','P4-O2','FP2-F8','F8-T8','T8-P8-0','P8-O2','FZ-CZ','CZ-PZ','P7-T7','T7-FT9','FT9-FT10','FT10-T8','T8-P8-1']\n",
    "    data = data.filter(items=common_cols) #* Filter the data to include only the common channels\n",
    "    data = add_seizure(data, file) #* Add the seizure data to the dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "test = read_edf(records_path[0]) #* test = (n_epochs, n_channels, n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test #? time is on seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing and training sets<br>\n",
    "* Total Normal = 545<br>\n",
    "* Total Seizure = 142<br>\n",
    "So we can use around 84% of this data for training ang remaining 16% for testing<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? Create the Feed Forward Neural Network Model\n",
    "class FFNN_Model(nn.Module):\n",
    "    def __init__(self, in_channels, h1, h2):\n",
    "        super(FFNN_Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, 16)\n",
    "        self.fc4 = nn.Linear(16, 8)\n",
    "        self.out = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on one patient file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "torch.manual_seed(seed) #* Set the seed for reproducibility\n",
    "\n",
    "#? Create the model\n",
    "data = pd.concat([read_edf(records_path[2]), read_edf(records_path[3])])\n",
    "model = FFNN_Model(data.shape[1]-2, 64, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X = data.drop(columns=['time', 'seizure']).values\n",
    "y = data['seizure'].values\n",
    "\n",
    "#? Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "#? Convert the data to tensors\n",
    "X_train = torch.FloatTensor(X_train).to(device)\n",
    "X_test = torch.FloatTensor(X_test).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 500\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    losses.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} Loss: {loss.item()}')\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f\"{i+1}: {str(y_val)} \\t {y_test[i]}\")\n",
    "        if y_test[i] == 1 and y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f\"Total correct: {correct}\")\n",
    "print(f\"Accuracy: {correct/len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLEARLY FCNN IS CANT BE USED FOR THIS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_testing(data):\n",
    "    X = data.drop(columns=['time', 'seizure']).values\n",
    "    y = data['seizure'].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.16, random_state=seed, shuffle=False)\n",
    "\n",
    "    # Reshape the data for RNN input\n",
    "    X_train = torch.FloatTensor(X_train).reshape(-1, 256, X_train.shape[1]).to(device)\n",
    "    X_test = torch.FloatTensor(X_test).reshape(-1, 256, X_test.shape[1]).to(device)\n",
    "    y_train = torch.FloatTensor([y_train[i:i + 256].sum() for i in range(0, len(y_train), 256)]).to(device)\n",
    "    y_test = torch.FloatTensor([y_test[i:i + 256].sum() for i in range(0, len(y_test), 256)]).to(device)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, criterion, optimizer, X_train, y_train, epochs=30):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train).squeeze()\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch} Loss: {loss.item()}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Plot the training loss\n",
    "    plt.plot(range(epochs), losses)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_val = model(X_test).squeeze()\n",
    "        predictions = torch.sigmoid(y_val) >= 0.5\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i] == 1:\n",
    "                total += 1\n",
    "                if predictions[i] == y_test[i]:\n",
    "                    correct += 1\n",
    "\n",
    "    print(f\"Correct:{correct}/Total:{total}\")\n",
    "\n",
    "    try:\n",
    "        return correct/total\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecNet():\n",
    "    input_size = 22  # Exclude 'time' and 'seizure' columns\n",
    "    hidden_size = 64\n",
    "    num_layers = 2\n",
    "    num_classes = 1\n",
    "    skipped_files = []\n",
    "\n",
    "    model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for file in records_seizure_path:\n",
    "        data = read_edf(file)\n",
    "        if data.shape[1]-2 != input_size:\n",
    "            skipped_files.append(file)\n",
    "            continue\n",
    "        X_train, X_test, y_train, y_test = split_training_testing(data)\n",
    "\n",
    "        model = train_model(model, criterion, optimizer, X_train, y_train, epochs=50)\n",
    "\n",
    "    accuracy = evaluate_model(model, X_test, y_test)\n",
    "    print(f\"Skipped files: {skipped_files}\")\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"main\")\n",
    "    # FeedForward()\n",
    "    RecNet()\n",
    "    # LongShort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__:\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
