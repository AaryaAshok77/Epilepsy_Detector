{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Dataset Acquisition & Understanding**\n",
    "\n",
    "- **Download the CHBM-MIT EEG dataset:** Go to [https://physionet.org/content/chbmit/](https://physionet.org/content/chbmit/) and follow the instructions to download the dataset.\n",
    "- **Familiarize yourself with the data:**\n",
    "  - Open the downloaded files in a text editor or use data exploration tools in Python like pandas.\n",
    "  - Identify the format of the data (e.g., EDF, CSV).\n",
    "  - Understand the channels, sampling rate, and meaning of each column in the data.\n",
    "  - Explore the provided annotation files and seizure labels.\n",
    "- **Choose environment:**\n",
    "  - **Macbook Air M1:** Install Python (version 3.7 or above) and the necessary libraries (see **Step 4**) using tools like `pip` or `homebrew`.\n",
    "  - **Google Colab:** No installation needed, access Colab notebooks through [https://research.google.com/colaboratory/](https://research.google.com/colaboratory/) and import the libraries directly in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Preprocessing & Feature Extraction**\n",
    "\n",
    "- **Import libraries:**\n",
    "\n",
    "```python\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "- **Load data:** Use mne functions like `mne.io.read_raw_edf` to load the EEG data.\n",
    "\n",
    "```python\n",
    "raw = mne.io.read_raw_edf('chb01_01.edf', preload=False)  # Replace with your filename\n",
    "```\n",
    "\n",
    "- **Cleaning and Filtering:**\n",
    "  - Apply basic filtering (e.g., notch filter to remove power line noise) using `raw.filter()`.\n",
    "  - Perform visual inspection (e.g., plotting the data) to identify and remove artifacts like muscle movement or equipment noise.\n",
    "  - Learn about advanced cleaning techniques like Independent Component Analysis (ICA) for advanced noise reduction.\n",
    "- **Resampling:**\n",
    "  - If needed, resample the data to a consistent sampling rate using `raw.resample()`\n",
    "- **Segmentation:**\n",
    "  - Use event markers or annotations to segment the data into relevant epochs (e.g., ictal and interictal periods) using `mne.Epochs`.\n",
    "  - Consider different epoch lengths based on your chosen features and seizure type.\n",
    "- **Feature Extraction:**\n",
    "  - Implement functions to calculate desired time-domain features (e.g., mean, variance, amplitude) and frequency-domain features (e.g., power spectral density using FFT) using libraries like NumPy or scikit-learn.\n",
    "  - Explore libraries like NeuroKit2 for specific EEG feature extraction functionalities.\n",
    "  - Consider advanced features like connectivity metrics (coherence, phase lag) using MNE-Python for later source localization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Binary Classification**\n",
    "\n",
    "- **Data splitting:** Use scikit-learn's functions (e.g., `train_test_split`) to split your labeled data (epileptic vs. non-epileptic) into training (60%), validation (20%), and testing (20%) sets.\n",
    "- **Model selection:**\n",
    "  - **Start simple:**\n",
    "    - **Logistic Regression:**\n",
    "      ```python\n",
    "      from sklearn.linear_model import LogisticRegression\n",
    "      model = LogisticRegression(solver='lbfgs')\n",
    "      model.fit(X_train, y_train)  # X_train and y_train are your training data and labels\n",
    "      ```\n",
    "    - **Support Vector Machine (SVM):**\n",
    "      ```python\n",
    "      from sklearn.svm import SVC\n",
    "      model = SVC(kernel='linear')\n",
    "      model.fit(X_train, y_train)\n",
    "      ```\n",
    "  - **Explore neural networks if needed:**\n",
    "    - **Convolutional Neural Networks (CNNs):** Learn about building and training CNNs for time-series data using PyTorch tutorials and examples.\n",
    "    - **Long Short-Term Memory (LSTM) networks:** Explore LSTMs for capturing temporal dependencies in EEG data if applicable.\n",
    "- **Training:** Use PyTorch's functionalities to train your chosen model on the training data. Set up a training loop with loss function (e.g., binary cross-entropy), optimizer (e.g., Adam), and training epochs.\n",
    "\n",
    "```python\n",
    "# Example training loop for Logistic Regression\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# ... define your model and data loaders\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of CHBM-MIT EEG Dataset\n",
    "### Dataset: Scalp EEG Recordings from Children with Intractable Seizures\n",
    "\n",
    "This dataset contains electroencephalography (EEG) recordings from **22 subjects** with intractable seizures. The data is grouped into **23 cases**, with some subjects contributing multiple recordings.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **Subjects:** 22 (5 males, 17 females; ages 1.5-22)\n",
    "* **Cases:** 23 (chb01 to chb23)\n",
    "* **Sampling Frequency:** 256 Hz\n",
    "* **Recordings per Subject:** 9-42 (each lasting 1-4 hours)\n",
    "* **Seizures:** 198 total (182 in original set)\n",
    "* **File Types:**\n",
    "    * `.edf`: Raw EEG data files (664 total)\n",
    "    * `.seizure`: Annotations for seizure start and end times (for files containing seizures)\n",
    "\n",
    "**Additional Notes:**\n",
    "\n",
    "* Case `chb21` is from the same subject as `chb01`, but recorded 1.5 years later.\n",
    "* Case `chb24` is not included in the `SUBJECT-INFO` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: ('/Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb01_01.edf', '/Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb01_03.edf')\n"
     ]
    }
   ],
   "source": [
    "chb01_01 = glob('/Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb01_01.edf')\n",
    "chb01_03 = glob('/Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb01_03.edf')\n",
    "print(f\"print: {chb01_01[0], chb01_03[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edf(file):\n",
    "    data = mne.io.read_raw_edf(file, preload=True) #? Read the edf file\n",
    "    data.set_eeg_reference() #? Set the EEG reference which is the average of all the channels\n",
    "    data.filter(l_freq=0.5, h_freq=45)  #? Filter the data to remove noise\n",
    "    epoch = mne.make_fixed_length_epochs(data, duration=5, overlap=2) #? Used to create epochs of the data with a fixed length of 5 seconds and an overlap of 2 seconds\n",
    "    data = epoch.get_data() #? Get the data from the epochs, convert it to a numpy array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "data_chb01_01 = read_edf(chb01_01[0])\n",
    "data_chb01_03 = read_edf(chb01_03[0])\n",
    "\n",
    "print(data_chb01_01.shape)\n",
    "print(data_chb01_03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 23, 1280)\n",
      "(1199, 23, 1280)\n"
     ]
    }
   ],
   "source": [
    "print(data_chb01_01.shape)\n",
    "print(data_chb01_03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb01_15.seizures.edf\n",
      "<Annotations | 0 segments>\n"
     ]
    }
   ],
   "source": [
    "chb01_03s = glob('/Users/aaryaashokk/Documents/Coding/Projects/DataSets/chb01_15.seizures.edf')\n",
    "print(chb01_03s[0])\n",
    "temp = mne.read_annotations(chb01_03s[0])\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
